

train.csv : 훈련용 데이터 (1개 파일)

- 3년(Day 0~ Day1094) 동안의 기상 데이터, 발전량(TARGET) 데이터



test.csv : 정답용 데이터 (81개 파일)

- 2년 동안의 기상 데이터, 발전량(TARGET) 데이터 제공

- 각 파일(*.csv)은 7일(Day 0~ Day6) 동안의 기상 데이터, 발전량(TARGET) 데이터로 구성

- 파일명 예시: 0.csv, 1.csv, 2.csv, …, 79.csv, 80.csv (순서는 랜덤이므로, 시계열 순서와 무관)

- 각 파일의 7일(Day 0~ Day6) 동안의 데이터 전체 혹은 일부를 인풋으로 사용하여, 향후 2일(Day7 ~ Day8) 동안의 30분 간격의 발전량(TARGET)을 예측 (1일당 48개씩 총 96개 타임스텝에 대한 예측)



sample_submission.csv : 정답제출 파일

- test 폴더의 각 파일에 대하여, 시간대별 발전량을 9개의 Quantile(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)에 맞춰 예측

- “파일명_날짜_시간” 형식(예시: 0.csv_Day7_0h00m ⇒ 0.csv 파일의 7일차 0시00분 예측 값)에 유의


///////////////////////////////////////////////////////////

Hour - 시간
Minute - 분
DHI - 수평면 산란일사량(Diffuse Horizontal Irradiance (W/m2))
DNI - 직달일사량(Direct Normal Irradiance (W/m2))
WS - 풍속(Wind Speed (m/s))
RH - 상대습도(Relative Humidity (%))
T - 기온(Temperature (Degree C))
Target - 태양광 발전량 (kW)


예시로 제시된 지역의 기상 데이터와 과거 발전량 데이터를 활용하여, 시간대별 태양광 발전량을 예측

/////////////////////////////////////////////////

기대효과: 시간대별 소비자 그룹의 전력소비량 예측 데이터와 결합하여 가장 효율적인 시간대별 태양광 발전과 국가 전력망을 조합 가능. 각 소비자 그룹에 최적화된 공급계획 수립 가능.

//////////////////////////////////////////////////////////


정답양식

30분간격의예측값에대한
10 %, 20 %,...90 % quantile

Pinballloss

High penalty to underforecast above 50 % percentiles
High penalty to overforecast below
50 % percentiles 높은 quantile 값에서는 측정된 값이 예측값보다 낮아야 함 >> overforecast 유도
반대로 낮은 quantile값에서는 측정된 값이 예측값보다 높아야 함 >> underforecast 유도

Lτ(y,z) = if y>=z, (y-z)τ
        = if z>y , (z-y)(1-τ)

τ: 퀀타일 값(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)

y: 실제 값

z: 퀀타일 예측값

Lτ: pinball loss 함수

->  퀀타일값 9개에 대해서 9번 예측

https://medium.com/analytics-vidhya/a-tutorial-on-quantile-regression-quantile-random-forests-and-quantile-gbm-d3c651af7516

Pinball Loss에 대한 Kaggle discussion을 공유합니다.

Loss function에 대한 수치적인 이해가 있다면 성능을 높이기에 더욱 유리하지 않을까 싶네요!

https://www.kaggle.com/c/m5-forecasting-uncertainty/discussion/137098#779205

////////////////////////////////////////////////////////

-> 기본적인 태양광 발전의 과정은 광전효과를 통해 생성되므로, 패널에 닿는 일사량이 가장 중요할 것이라 생각된다.

DHI - 수평면 산란일사량(Diffuse Horizontal Irradiance (W/m2))
DNI - 직달일사량(Direct Normal Irradiance (W/m2))

DHI 산란 일사량을 살펴본 결과 5만2천개의 데이터 중에서 3만개의 데이터가 0의 값을 갖는다.
산란 일사량이란  대기, 구름 등에 의해 다중 산란된 태양복사

DNI 직달 일사량은 대기에 산란, 흡수, 감퇴되지 않고, 지표면에 수직으로 도달하는 일사
마찬가지로 약 3만개의 데이터가 0의 값을 갖는다.

DHI와 DNI를 통틀어 전천일사 (global solar radiation)이라 한다. -> GSR 이라 하겠다.
-> 전천 일사량 컬럼을 보는것도 중요할 것 같다.
합쳐서 GSR이라 했는데 26600개의 데이터가 0개로, 둘 따로 봤을떄보다 0의 값을 갖는 데이터가 적어졌다.

-> DNI와 DHI를 합친 GSR과 TARGET과의 관계를 살펴본 결과, 따로본것과는 다르게 좀더 명확한 관계를 얻을 수 있었다.

-> GSR이 0인 데이터들은 모두 TARGET이 0이라는 것을 확인했다.

-> 그렇다면 GSR이 0인값들의 TARGER이 0이 되므로 이상치로 제거를 한 뒤 생각을 해야 하는가? -> 고려해봐야 할 것 같다.

-> GSR이 0인 경우에만 TARGET이 0이 아니라는 것을 확인 하였다. -> 이 값들을 이상치로 제거하는 것이 좋을 것 같다.

////////////////////////////////////////////////////////////////////////////////////////////

-> 나머지 요인들은 어떤 효과가 있는가? 온도, 풍속, 습도가 일사량에 미치는 영향은 무엇인가?

-> 변수들간의 다중공선성을 제거해야한다. 공부좀 해봐야 할것 같다.

각 독립변수들간의 상관관계가 존재하지 않도록 해야한다.

    결정계수 𝑅^2값은 높지만 독립변수의 p-value 값이 커서 개별 인자들이 유의하지 않는 경우
    독립변수들간의 상관계수를 구하여 상관성이 높은 경우
    분산팽창요인(Variance Inflation Factor)을 구하여 값이 10이 넘는 경우

    상관관계가 높은 독립 변수 중 하나 혹은 일부를 제거한다.
    변수를 변형시키거나 새로운 관측치를 이용한다.
    자료를 수집하는 현장의 상황을 보아 상관관계의 이유를 파악하여 해결한다.

///////////////////////////////////////////////////////////////////////////////////////////////

이 값들을 제거한 데이터 프레임을 data6에 저장.

-> TARGET이 0이 아닌 값들의 분포를 시간별로 살펴본 결과, 05시 - 19시 까지로 해가 떠있는 시간에만 유효했다.

-> 시간별 값들의 분포도 확인하고 싶다.

-> 시간별로의 평균 TARGET분포를 확인해본 결과, 표준분포와 매우 유사한 형태를 이루고 있다는 것을 알 수 있다.

-> GSR은 좀더 종의 형태를 이루고 있었다. 다른 요인들의 그래프를 확인해봐야 할 것 같다.

-> DNI의 그래프가 좀더 종형에 가까웠고, DHI의 그래프가 좀더 뾰족한 형태를 이루었다. -> DHI의 형태를 좀더 따라는듯???

-> T와 WS, RH의 플랏 형태도 살펴 보았지만 어떠한 영향이 있는지 잘 알 수 없었다.

이 변수들 사이의 관계를 살펴보자. -> 상관계수를 살펴본 결과
            DHI	        DNI	        GSR	        WS	        RH	        T	        TARGET
    DHI	    1.000000	0.808143	0.899409	0.870885	-0.932667	0.475339	0.975961
    DNI	    0.808143	1.000000	0.984302	0.910715	-0.808494	-0.044881	0.893024
    GSR	    0.899409	0.984302	1.000000	0.936841	-0.879493	0.109131	0.955199
    WS	    0.870885	0.910715	0.936841	1.000000	-0.773976	0.036508	0.894074
    RH	    -0.932667	-0.808494	-0.879493	-0.773976	1.000000	-0.456722	-0.914305
    T	    0.475339	-0.044881	0.109131	0.036508	-0.456722	1.000000	0.359028
    TARGET	0.975961	0.893024	0.955199	0.894074	-0.914305	0.359028	1.000000

의 상관계수를 나타냈고, 별로 관계가 없다고 판단되는 변수들은 T(온도)와 DNI, GSR, WS 정도이다.
그래도 DHI와 GSR은 어느정도의 관계가 있다고 생각된다. 다른 변수들 사이의 관계는 꽤나 큰것으로 판단된다.

-> 근데 이 값들은 시간대별로의 평균값을 받아 계산한 결과이므로, 이 평균값들이 타당한지 확인해봐야 한다.

시간대별로 나눈것이 아닌 모든 값들에 대해서 상관계수를 확인해본결과

            DHI	        DNI	        WS	        RH	        T	        TARGET
    DHI	    1.000000	0.288294	0.203286	-0.478503	0.457813	0.666908
    DNI	    0.288294	1.000000	0.219555	-0.611184	0.402460	0.833547
    WS	    0.203286	0.219555	1.000000	-0.230035	0.027693	0.238521
    RH	    -0.478503	-0.611184	-0.230035	1.000000	-0.532777	-0.677178
    T	    0.457813	0.402460	0.027693	-0.532777	1.000000	0.561990
    TARGET	0.666908	0.833547	0.238521	-0.677178	0.561990	1.000000

상관관계들 사이에 어느정도 관계는 있는것으로 확인되고, 그중 RH-DHI, RH-DNI, DHI-T, DHI-TARGET, DNI-TARGET
사이의 상관계수는 꽤나 큰것으로 간주가 된다.

//////////////////////////////////////////////////////////////////////////////////////////

해가 떠있는 시간과 온도 사이의 관계를 보기 위해, 온도가 0보다 작은 경우 TARGET을 살펴본 결과
75%까지는 0의 값을 가지고 있었다. -> 온도와 타겟, GSR사이의 관계를 한번 화야할 것 같다.

-> groupbytime에서는 T가 0도 이하인 값이 존재하지 않았다.

min 10에서 min 17정도의 분포를 나타냈다.

다중회귀를 통해 얼추 핏을 맞추어 봤따.

    Intercept   -33.238542
    DHI           0.293410
    DNI           0.071277
    WS          -11.796345
    RH            0.490932
    T             0.644327

-> 평균값들에 대해서 피팅을 한 값이므로, 전체 데이터에 대해서는 잘 맞지 않았다.
음수값이 나오면 안되는데 음수가 크게 나오는 경우도 발생하였다.

전체 데이터에 대해서 다중회귀 모델을 적용시켜보자 -> 데이터의 분포가 정규분포여야 적합한가?

일단 전체 데이터에 대해서 다중회귀를 시행한 결과

    Intercept   -15.942528
    DHI           0.123476
    DNI           0.056368
    WS            0.591370
    RH            0.003073
    T             0.508868

    로 평균값들에 대해서 회귀를 취한 값들과 매우 달랐다.
    얼추 맞기는 하지만, 아직도 음수의 값은 나왔고, 실제 데이터가 좀더 종형인 반면, 예측 값들은 뾰족한 형태에 가까웠다.

-> 데이터들의 분포가 정규분포와는 거리가 먼 형태였다.

-> day, hour, min 모두 포함해서 해볼까?

//////////////////////////////////////////////////////

groupbby를 날자별로 하여 날자별 평균값을 살펴보자

-> 날자별 평균값들로 분포를 확인해 본 결과, DHI와 T, TARGET에서는 주기적인 반복이 관찰 되었다.
하지만 다른 컬럼들에서는 뚜렷한 주기성을 확인하지 못했다.

